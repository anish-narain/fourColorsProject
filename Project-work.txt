Tools used:
------------

BeautifulSoup:
https://beautiful-soup-4.readthedocs.io/en/latest/
https://www.scrapingbee.com/blog/python-web-scraping-beautiful-soup/

YAKE Keyword extraction:
https://github.com/LIAAD/yake

BERT:
https://medium.com/@samia.khalid/bert-explained-a-complete-guide-with-theory-and-tutorial-3ac9ebc8fa7c
https://jalammar.github.io/illustrated-bert/
https://bamblebam.medium.com/generating-text-similarity-scores-using-bert-44a78df1f9c7

Transformers with BERT:
https://mccormickml.com/2019/07/22/BERT-fine-tuning/
https://www.thepythoncode.com/article/finetuning-bert-using-huggingface-transformers-python

Cosine similarity:
https://towardsdatascience.com/nlp-text-similarity-how-it-works-and-the-math-behind-it-a0fb90a05095
https://pythonwife.com/cosine-similarity-in-natural-language-processing/

Development Environment:
------------------------
1. Python3.7.5 (It didn't work with 3.8.9 so moved down)
2. Set up virtual environment

	Create the python virtual environment.
   		$ python3 -m venv venv
	Activate the virtual environment.
   		$ source venv/bin/activate
   		(venv) $

3. use [pip install] to install the dev dependencies:

	pip install beautifulsoup4	
	pip install requests
	pip install git+https://github.com/LIAAD/yake
	pip install sentence-transformers
	pip install sklearn
	pip install transformers


4. create the following folders: faqQuestionContent, faqAnswerContent, faqQuestionKeywords, faqAnswerKeywords at the same level as python programs as so:

	(venv) anishnarain@Anishs-MBP nlp-project % mkdir faqQuestionContent
	(venv) anishnarain@Anishs-MBP nlp-project % mkdir faqAnswerContent
	(venv) anishnarain@Anishs-MBP nlp-project % mkdir faqQuestionKeywords
	(venv) anishnarain@Anishs-MBP nlp-project % mkdir faqAnswerKeywords

5. Developed on macOS, not tested on Windows

Overview:
---------
A. Scraper Program
1. Use BeautifulSoup to fetch the relevant links from main FAQ page
2. Go to the corresponding link and fetch the relevant contents
3. Put the FAQ question and the FAQ answer in text files.

(venv) anishnarain@Anishs-MBP nlp-project % python3 scraper.py
Successfully extracted the information to faqQuestionContent and faqAnswerContent folders

B. KeywordExtractor program
4. Read the FAQ Question and the FAQ Answer and extract the keywords in the corresponding files.

(venv) anishnarain@Anishs-MBP nlp-project % python3 keywords-extractor.py 
Successfully generated the keywords in faqQuestionKeywords and faqAnswerKeywords folders


C. Cosine-BERT Function
5. Generate BERT Vector for the two sentences and then calculate the cosine similarity between them.

D: Chat program
6. Take user input and then return 3 top matches as per following algorithm
  a) BERT+Cosine similarity between the query and the FAQ Question
  b) BERT+Cosine similarity between the query and the FAQ Question Keywords, extracted in step 3.
  c) BERT+Cosine similarity between the query and the FAQ Answer Keywords, extracted in step 3.
  PS: BERT doesnt work well with large text, so query and FAQ Answer matching gives poor results, hence it has been ignored.

(venv) anishnarain@Anishs-MBP nlp-project % python3 chat.py 
What is your query? How to install CATIA

  Now calculating 3 top BERT+Cosine similarity between the query and the FAQ Question
  https://www.technia.co.uk/faqs/issue-with-catia-v5/  : [0.7485968]
  https://www.technia.co.uk/faqs/installing-catia-v5/  : [0.71425736]
  https://www.technia.co.uk/faqs/lum-alongside-catia-v5-r21-r22/  : [0.70465267]


  Now calculating 3 top BERT+Cosine similarity between the query and the FAQ Question Keywords, extracted in step 3.
  https://www.technia.co.uk/faqs/installing-catia-v5/  : [0.76934016]
  https://www.technia.co.uk/faqs/installing-catia-v5-documentation/  : [0.7278298]
  https://www.technia.co.uk/faqs/issue-with-catia-v5/  : [0.68754125]


  Now calculating 3 top BERT+Cosine similarity between the query and the FAQ Answer Keywords, extracted in step 3.
  https://www.technia.co.uk/faqs/installing-catia-v5-documentation/  : [0.6612614]
  https://www.technia.co.uk/faqs/obtaining-a-dsls-pc-id/  : [0.61133546]
  https://www.technia.co.uk/faqs/lum-alongside-catia-v5-r21-r22/  : [0.60415435]


Further Work:
-------------
1. Exception handling
2. How to add context to BERT model (eg add/remove domain keywords, manually)
3. Optimise the different variables
  a) YAKE parameters
  b) BERT model
4. Testing to determine the best method
5. Can we make it quicker

Useful Links
https://medium.com/@samia.khalid/bert-explained-a-complete-guide-with-theory-and-tutorial-3ac9ebc8fa7c
https://www.thepythoncode.com/article/finetuning-bert-using-huggingface-transformers-python
https://mccormickml.com/2019/07/22/BERT-fine-tuning/#what-is-bert
